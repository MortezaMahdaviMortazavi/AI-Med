{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9vzfeNp64UfMrl8ItS64Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MortezaMahdaviMortazavi/DeepLearning-Introduction/blob/master/RNN/TokenLevelRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zCJRZA9eqbYd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getRandomChunk(text,chunk_len=500):\n",
        "  start_idx = np.random.randint(0,len(text)-chunk_len) # because if we set 0 to len(text) it may random chunk length become less than chunk_len\n",
        "  end_idx = start_idx + chunk_len + 1\n",
        "  theChunk = text[start_idx:end_idx]\n",
        "  return theChunk\n",
        "\n",
        "# getRandomChunk(corpus)"
      ],
      "metadata": {
        "id": "uRf2exS-SloF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def char_to_tensor(string):\n",
        "  tensor = torch.zeros((len(string))).long()\n",
        "  for c in range(len(string)):\n",
        "    tensor[c] = all_characters.index(string[c])\n",
        "  return Variable(tensor)"
      ],
      "metadata": {
        "id": "wwkAPA6yUJGc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for word to vector you shoud get some sentences and isolate words in count of n and create tensor "
      ],
      "metadata": {
        "id": "diWqx4UGcgTz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_TOKEN = 0\n",
        "EOS_TOKEN = 1\n",
        "class Language:\n",
        "  def __init__(self,corpus,name):\n",
        "    self.name = name # name of target language\n",
        "    self.dataset = corpus.split()\n",
        "    self.vocab = len(sorted(corpus)) # all of unique character\n",
        "    self.word2count = {}\n",
        "    self.word2idx = {\n",
        "        \"SOS_TOKEN\":SOS_TOKEN,\n",
        "        \"EOS_TOKEN\":EOS_TOKEN\n",
        "    }\n",
        "    self.idx2word = {\n",
        "        SOS_TOKEN:\"SOS_TOKEN\",\n",
        "        EOS_TOKEN:\"EOS_TOKEN\"\n",
        "    }\n",
        "\n",
        "  def tokenizer(self):\n",
        "    current_idx = 2\n",
        "    for word in self.dataset:\n",
        "      if word not in self.word2idx:\n",
        "        # words = word.replace(string.punctuation,'')\n",
        "        self.word2idx[word] = current_idx\n",
        "        self.idx2word[current_idx] = word\n",
        "        self.word2count[word] = 1\n",
        "        current_idx += 1\n",
        "      else:\n",
        "        self.word2count[word] += 1\n",
        "\n",
        "  @property\n",
        "  def getWord2Idx(self):\n",
        "    return self.word2idx\n",
        "  @property\n",
        "  def getIdx2Word(self):\n",
        "    return self.idx2word\n",
        "\n",
        "  @property\n",
        "  def getWord2Count(self):\n",
        "    return self.word2count\n",
        "\n",
        "  @property\n",
        "  def getCharacters(self):\n",
        "    return self.vocab\n",
        "\n",
        "corpus = open('shakespeare.txt','r').read()\n",
        "language = Language(corpus=corpus,name='English')\n",
        "corpus.split('\\n')[:10]"
      ],
      "metadata": {
        "id": "JLXMA7YhuiUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b319ed3-255d-4deb-aa51-c22ad2000592"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['THE SONNETS',\n",
              " '',\n",
              " 'by William Shakespeare',\n",
              " '',\n",
              " 'From fairest creatures we desire increase,',\n",
              " \"That thereby beauty's rose might never die,\",\n",
              " 'But as the riper should by time decease,',\n",
              " 'His tender heir might bear his memory:',\n",
              " 'But thou contracted to thine own bright eyes,',\n",
              " \"Feed'st thy light's flame with self-substantial fuel,\"]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,output_size,num_layers):\n",
        "    super(RNN,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    self.encoder = nn.Embedding(input_size,hidden_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.lstm = nn.LSTM(hidden_size,hidden_size,num_layers,batch_first=True)\n",
        "    self.decoder = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "  def forward(self,X,hidden,cell):\n",
        "    X = X.to(self.device)\n",
        "    output = self.encoder(X)\n",
        "    output = self.dropout(output)\n",
        "    output , (hidden,cell) = self.lstm(output.unsqueeze(1),(hidden,cell))\n",
        "    output = self.decoder(output.reshape(output.shape[0],-1))\n",
        "    # output = self.decoder(output)\n",
        "    return output , hidden , cell\n",
        "    \n",
        "\n",
        "  def init_hidden(self,batch_size):\n",
        "    hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size).to(self.device)\n",
        "    cell = torch.zeros(self.num_layers,batch_size,self.hidden_size).to(self.device)\n",
        "\n",
        "    hidden = Variable(hidden)\n",
        "    cell = Variable(cell)\n",
        "    return hidden , cell\n"
      ],
      "metadata": {
        "id": "miXhMmmo0M8i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_testing():\n",
        "  X = word2vec(lang=language,sentences=sentences)\n",
        "  model = RNN(len(X),len(X),len(X),num_layers=25)\n",
        "  hidden , cell = model.init_hidden(1)\n",
        "  out = model.forward(X,hidden,cell)\n",
        "  print(f\"output shape is {out.shape}\")\n",
        "  print(f\"hidden and cell shape is {hidden.shape}\")\n",
        "  print(f\"out is {out}\")\n",
        "# X = word2vec(lang=language,sentences=sentences)\n",
        "# model = RNN(len(word2idx),len(X),len(X),num_layers=25)\n",
        "# hidden , cell = model.init_hidden(100)\n",
        "# model.forward(X,hidden,cell)[0]"
      ],
      "metadata": {
        "id": "d9xgXFCH3J_W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator:\n",
        "  def __init__(self,file):\n",
        "    super().__init__()\n",
        "    self.n_sentences = 15\n",
        "    self.max_words = 100\n",
        "    self.batch_size = 1\n",
        "    self.hidden_size = 256\n",
        "    self.num_layers = 10\n",
        "    self.lr = 0.005\n",
        "    self.epochs = 1000\n",
        "    self.sentences = self.corpusProcessing(file)[0]\n",
        "    self.corpus = self.corpusProcessing(file)[1]\n",
        "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    self.language = None  \n",
        "    self.rnn = None\n",
        "    self.optimizer = None\n",
        "    self.criterion = None\n",
        "    \n",
        "\n",
        "  def setModel(self,input_size,hidden_size,num_layers):\n",
        "    self.rnn = RNN(\n",
        "        input_size=input_size,\n",
        "        hidden_size=hidden_size,\n",
        "        output_size = input_size,\n",
        "        num_layers = num_layers\n",
        "      )\n",
        "  \n",
        "  def tokenize(self):\n",
        "    self.language.tokenizer()\n",
        "    \n",
        "  def setLanguage(self,name):\n",
        "    self.language = Language(self.corpus,name)\n",
        "    self.tokenize()\n",
        "  \n",
        "  def setOptimizer(self):\n",
        "    self.optimizer = torch.optim.Adam(filter(\n",
        "        lambda p:p.requires_grad,self.rnn.parameters()),lr=self.lr)\n",
        "    \n",
        "  def setCriterion(self):\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "  def corpusProcessing(self,file):\n",
        "    corpus = open(file,'r').read() # read text file\n",
        "    corpus.translate(str.maketrans('','',string.punctuation)) # try to eliminate punctuations\n",
        "    new_corpus = re.sub(r'[^\\w\\s]','',corpus) # eliminate all punctuations that remind\n",
        "    all_characters = string.printable # all characters that exists in keyboard\n",
        "    n_characters = len(all_characters) # length of characters\n",
        "    sentences = new_corpus.split('\\n') # split corpus base on sentences\n",
        "    for item in sentences:\n",
        "      if item == '' or item == ' ' or item == '  ' or item == '   ': # delete all sentences that are empty\n",
        "        sentences.pop(sentences.index(item))\n",
        "    return sentences , new_corpus\n",
        "\n",
        "\n",
        "\n",
        "  def getChunkOfSentences(self):\n",
        "    start_idx = np.random.randint(0,len(self.sentences)-self.n_sentences)\n",
        "    end_idx = start_idx + self.n_sentences + 1\n",
        "    chunk_sentences = self.sentences[start_idx:end_idx]\n",
        "    theChunk = ''\n",
        "    for sen in chunk_sentences:\n",
        "      theChunk += (sen) + ' '\n",
        "    return theChunk\n",
        "\n",
        "  # def word2vec(self,lang,chunk_corpus):\n",
        "  #   # Default argument values are evaluated at function define-time, but self is an argument only available at function call time.\n",
        "  #   # Thus arguments in the argument list cannot refer each other\n",
        "  #   # chunk_corpus = getChunkOfSentences(sentences=sentences,n_sentence=15) # get a chunk of corpus\n",
        "  #   separate_words = chunk_corpus.split()[:self.max_words] # separate words in number of max_length\n",
        "  #   # print(len(separate_words))\n",
        "  #   tensor = torch.zeros(self.max_words).long() # create a tensor of zeros in length of max_length\n",
        "  #   word2idx = lang.getWord2Idx\n",
        "  #   for idx in range(self.max_words): \n",
        "  #     tensor[idx] = word2idx[separate_words[idx]] # for each index of tensor,add word2idx relation index\n",
        "    \n",
        "  #   return tensor\n",
        "  def word2vec(self, lang, chunk_corpus):\n",
        "    separate_words = chunk_corpus.split()\n",
        "    tensor = torch.zeros(self.max_words).type(torch.LongTensor)\n",
        "    word2idx = lang.getWord2Idx\n",
        "    for idx in range(self.max_words):\n",
        "        if idx < len(separate_words):\n",
        "            tensor[idx] = word2idx[separate_words[idx]]\n",
        "    return tensor\n",
        "\n",
        "  def get_random_batch(self):\n",
        "    chunks = []\n",
        "    for i in range(self.batch_size):\n",
        "      chunk = self.getChunkOfSentences()\n",
        "      chunk = chunk.strip()\n",
        "      chunks.append(chunk)\n",
        "    # return chunks\n",
        "    tensor_input = torch.zeros(self.batch_size,self.max_words-1)\n",
        "    tensor_target = torch.zeros(self.batch_size,self.max_words-1)\n",
        "\n",
        "    for i in range(self.batch_size):\n",
        "      # w2vec = self.word2vec(lang=self.language,chunk_corpus=chunks[i])\n",
        "      # tensor_input[i,:] = w2vec[:-1]\n",
        "      # tensor_target[i,:] = w2vec[1:]\n",
        "      tensor_input[i,:] = self.word2vec(lang=self.language,chunk_corpus=chunks[i])[:-1]\n",
        "      tensor_target[i,:] = self.word2vec(lang=self.language,chunk_corpus=chunks[i])[1:]\n",
        "      # break\n",
        "      \n",
        "    tensor_input = tensor_input.long()\n",
        "    tensor_target = tensor_target.long()\n",
        "\n",
        "    return tensor_input , tensor_target\n",
        "\n",
        "        \n",
        "  def generate(self,initial_str='From some',predict_len=100,temperature=0.85):\n",
        "    hidden , cell = self.rnn.init_hidden(self.batch_size)\n",
        "    initial_input = self.word2vec(self.language,initial_str)\n",
        "    predicted = initial_str\n",
        "    for p in range(len(initial_str.split())-1):\n",
        "      _ , hidden,cell = self.rnn(\n",
        "          initial_input[p].view(1).to(self.device),hidden,cell\n",
        "      )\n",
        "    last_token = initial_input[-1]\n",
        "\n",
        "\n",
        "    for p in range(predict_len):\n",
        "      print(last_token , initial_input.shape)\n",
        "      break\n",
        "      out , hidden , cell = self.rnn(\n",
        "          last_token.view(1).to(self.device),hidden,cell\n",
        "      )\n",
        "      output_dist = out.data.view(-1).div(temperature).exp()\n",
        "      top_char = torch.multinomial(output_dist, 1)[0]\n",
        "      predicted_token = self.language.getIdx2Word[int(top_char.cpu())]\n",
        "      predicted += predicted_token\n",
        "      last_token = self.word2vec(self.language,predicted_token)\n",
        "\n",
        "    return predicted\n",
        "\n",
        "  def train(self):\n",
        "    self.rnn = self.rnn.to(self.device)\n",
        "    print(\"************ Training is start *********\")\n",
        "    for epoch in range(self.epochs+1):\n",
        "      # try:\n",
        "      inp , target = self.get_random_batch()\n",
        "      hidden , cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
        "\n",
        "      self.rnn.zero_grad()\n",
        "      loss = 0\n",
        "      inp = inp.to(self.device)\n",
        "      target = target.to(self.device)\n",
        "\n",
        "      for c in range(self.max_words-1):\n",
        "        # return self.rnn(inp[:,c],hidden,cell)\n",
        "        # break\n",
        "        # print(inp[:,c] , target[:,c])\n",
        "        out , hidden,cell = self.rnn(inp[:,c],hidden,cell)\n",
        "        loss += self.criterion(out,target[:,c])\n",
        "\n",
        "\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      loss = loss.item()/self.batch_size\n",
        "      # print(f\"loss is {loss}\")\n",
        "      \n",
        "      if epoch % 10 == 0:\n",
        "        print(f\"In epoch {epoch} loss is: {loss:2f}\")\n",
        "        self.generate()\n",
        "      # except:\n",
        "        # print(f\"ExceptionError raised in epoch {epoch}\")\n",
        "\n",
        "\n",
        "  # def generate(self, input_seq, max_length):\n",
        "  #   hidden,cell_state = self.rnn.init_hidden(self.batch_size)\n",
        "  #   output_seq = torch.tensor(input_seq).to(self.device)\n",
        "  #   for i in range(max_length):\n",
        "  #     print(output_seq.shape)\n",
        "  #     break\n",
        "  #     logits, (hidden, cell_state) = self.rnn.forward(output_seq, hidden, cell_state)\n",
        "  #     probs = torch.softmax(logits, dim=-1)\n",
        "  #     output_token = torch.multinomial(probs, 1).item()\n",
        "  #     if output_token == EOS_TOKEN:\n",
        "  #         break\n",
        "  #     output_seq = torch.cat([output_seq, torch.tensor([output_token]).to(self.device)])\n",
        "  #   return output_seq.tolist()\n",
        "\n",
        "\n",
        "  # def generate_text(self,input_text,max_length):\n",
        "  #   input_tokens = input_text.split() # tokenize input text\n",
        "  #   input_indices = [self.language.getWord2Idx[token] for token in input_tokens] # convert tokens to indices\n",
        "  #   output_indices = self.generate(input_indices,max_length=max_length)\n",
        "  #   output_tokens = [self.language.getIdx2Word[indice] for indice in output_indices]\n",
        "  #   return ''.join(output_tokens)\n"
      ],
      "metadata": {
        "id": "0oHTM5mlGEE1"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator('shakespeare.txt')\n",
        "generator.setLanguage('English')\n",
        "input_size = len(generator.language.getWord2Idx)\n",
        "hidden_size = 512\n",
        "num_layers = 15\n",
        "generator.setModel(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)\n",
        "generator.setOptimizer()\n",
        "generator.setCriterion()\n",
        "generator.language.getWord2Idx\n",
        "generator.train()"
      ],
      "metadata": {
        "id": "I2_QYtYaGFnR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "9e237f2a-974e-4012-9467-450502fad68a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************ Training is start *********\n",
            "In epoch 0 loss is: 806.611328\n",
            "tensor(0) torch.Size([100])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-0040156c19fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetWord2Idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-73-61be8bab1c9d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m       \u001b[0;31m# print(f\"loss is {loss}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "medrya1q-tHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}